library(rgdal)
library(raster)
library(sf)
library(sp)
library(RStoolbox)
library(rasterVis)
library(mapview)
library(tidyverse)
library(data.table)
library(caret)
library(cluster)
library(randomForest)
library(doParallel)
library(MLmetrics)
library(plotly)
library(nnet)
library(NeuralNetTools)
library(LiblineaR)


jp2_path <- "C:/Documents/sentinel2files"      #link to folder containing the sentinel 2 jp2 files
jp2_10m <- list.files(jp2_path, pattern = ".*jp2$", full.names = TRUE)
rst_lst <- lapply(jp2_10m, FUN = raster)


#create an extent for the area of interest
#may be tricky to get it to cover all the different raster resolutions
e <- as(extent(499980, 530290, 6027120, 6060250), 'SpatialPolygons')   #change the numbers to the corners of your extent
e <- st_as_sf(e)
st_crs(e) <- 32630

#create the raster brick
rst_crop_lst <- lapply(rst_lst, FUN = raster::crop, y = e)
names(rst_crop_lst) <- str_extract(sapply(rst_crop_lst, names), "B.{2}")
rst_crop_lst2 <- lapply(rst_crop_lst, FUN = raster::resample, y = rst_crop_lst[2][[1]], method="bilinear")
# print(rst_crop_lst)       #shows the metadata
viewRGB(brick(rst_crop_lst2[1:3]), r = 3, g = 2, b = 1)
brick_for_prediction <- brick(rst_crop_lst2)
# centre and scale which is apparently important for ML algorithms - see website
brick_for_prediction_norm <- normImage(brick_for_prediction)
names(brick_for_prediction_norm) <- names(brick_for_prediction)

# training shape preparation
# the training shapefile is a polygon shapefile with three attributes 'id' - id of each polygon, 'type' - name of the landtype, 'class' - numeric identifier for each landtype
poly <- rgdal::readOGR(dsn   = "c:/Documents/training_shape.shp", 
                       layer = "training_shape", 
                       stringsAsFactors = FALSE)
poly@data$id2 <- as.integer(factor(poly@data$class))
setDT(poly@data)
poly_utm <- sp::spTransform(poly, CRSobj = rst_crop_lst[[1]]@crs)

# rasterise polygons and extract band values to points
template_rst <- raster(extent(rst_crop_lst$B02), # band B2 has resolution 10 m
                       resolution = 10,
                       crs = projection(rst_crop_lst$B02))
poly_utm_rst <- rasterize(poly_utm, template_rst, field = 'id2')

poly_dt <- as.data.table(rasterToPoints(poly_utm_rst))
setnames(poly_dt, old = "layer", new = "id_cls")

points <- SpatialPointsDataFrame(coords = poly_dt[, .(x, y)],
                                 data = poly_dt,
                                 proj4string = poly_utm_rst@crs)

# can use two different approaches for next step:
# data table method
dt <- brick_for_prediction_norm %>% 
  raster::extract(y = points) %>% 
  as.data.table %>% 
  .[, id_cls := points@data$id_cls] %>%  # add the class names to each row
  merge(y = unique(poly@data), by.x = "id_cls", by.y = "id2", all = TRUE, sort = FALSE) %>% 
  .[, id_cls := NULL] %>% # this column is extra now, delete it
  .[, class := factor(class)]

# data frame method
dt2 <- brick_for_prediction_norm %>% 
  raster::extract(y = points) %>%  
  as.data.frame %>% 
  mutate(id_cls = points@data$id_cls) %>% # add the class names to each row
  left_join(y = unique(poly@data), by = c("id_cls" = "id2")) %>% #this one had errors with data types for id_cls
  mutate(id_cls = NULL) %>% # this column is extra now, delete it
  mutate(class = factor(class))

setDT(dt2)
#histograams of the bands
dt2 %>% 
  select(-c("class","type","id")) %>% 
  melt(measure.vars = names(.)) %>% 
  ggplot() +
  geom_histogram(aes(value)) +
  geom_vline(xintercept = 0, color = "gray70") +
  facet_wrap(facets = vars(variable), ncol = 3)

# split into test and train data
set.seed(321)
# A stratified random split of the data
idx_train <- createDataPartition(dt2$class,
                                 p = 0.7, # percentage of data as training
                                 list = FALSE)
dt_train <- dt2[idx_train]
dt_test <- dt2[-idx_train]
dt_train <- dt_train[,-c("id","type")]
dt_test <- dt_test[,-c("id","type")]

table(dt_train$class)
table(dt_test$class)

# create cross-validation folds (splits the data into n random groups)
n_folds <- 10
set.seed(321)
folds <- createFolds(1:nrow(dt_train), k = n_folds)
# Set the seed at each resampling iteration. Useful when running CV in parallel.
seeds <- vector(mode = "list", length = n_folds + 1) # +1 for the final model
for(i in 1:n_folds) seeds[[i]] <- sample.int(500, n_folds) #changed from 1000 to 500
seeds[n_folds + 1] <- sample.int(500, 1) # seed for the final model
#Note that, for each model, in trainControl we need to provide the followings:
  
ctrl <- trainControl(summaryFunction = multiClassSummary,
                      method = "cv",
                      number = n_folds,
                      search = "grid",
                      classProbs = TRUE, # not implemented for SVM; will just get a warning
                      savePredictions = TRUE,
                       index = folds,
                       seeds = seeds)

# Can use different methods from 'Caret' for the models.  Here are three examples: Random Forest, Neural Network, SVM 

#RANDOM FOREST 

dt_train$class <- make.names(dt_train$class)#caret didnt like the simple numbers as factors
dt_test$class <- make.names(dt_test$class)
# Register a doParallel cluster, using 3/4 (75%) of total CPU-s
cl <- makeCluster(3/4 * detectCores())
registerDoParallel(cl)
model_rf <- caret::train(class ~ . , method = "rf", data = dt_train,
                         importance = TRUE, # passed to randomForest()
                         # run CV process in parallel;
                         # see https://stackoverflow.com/a/44774591/5193830
                         allowParallel = TRUE,
                         tuneGrid = data.frame(mtry = c(2, 3, 4, 5, 8)),
                         trControl = ctrl)
stopCluster(cl); remove(cl)
# Unregister the doParallel cluster so that we can use sequential operations
# if needed; details at https://stackoverflow.com/a/25110203/5193830
registerDoSEQ()
saveRDS(model_rf, file = "C:/Documents/model_rf.rds")

#plot confusion matrix
cm_rf <- confusionMatrix(data = predict(model_rf, newdata = dt_test),
                         as.factor(dt_test$class))
cm_rf

#plots the importance of the different bands for predicting each class
caret::varImp(model_rf)$importance %>%
  as.matrix %>% 
  plot_ly(x = colnames(.), y = rownames(.), z = ., type = "heatmap",
          width = 350, height = 300)

randomForest::varImpPlot(model_rf$finalModel)


#SVM model

svm_grid <- expand.grid(cost = c(0.2, 0.5, 1),
                        Loss = c("L1", "L2"))

cl <- makeCluster(3/4 * detectCores())
registerDoParallel(cl)
model_svm <- caret::train(class ~ . , method = "svmLinear3", data = dt_train,
                          allowParallel = TRUE,
                          tuneGrid = svm_grid,
                          trControl = ctrl)
stopCluster(cl); remove(cl)
registerDoSEQ()
saveRDS(model_svm, file = "C:/Documents//model_svm.rds")
model_svm$times$everything#time elapsed
plot(model_svm)
cm_svm <- confusionMatrix(data = predict(model_svm, newdata = dt_test),
                          as.factor(dt_test$class))
cm_svm

#NEURAL NETWORK MODEL 

# Grid of tuning parameters
nnet_grid <- expand.grid(size = c(5, 10, 15),
                         decay = c(0.001, 0.01, 0.1))

cl <- makeCluster(3/4 * detectCores())
registerDoParallel(cl)
model_nnet <- train(class ~ ., method = 'nnet', data = dt_train,
                    importance = TRUE,
                    maxit = 1000, # set high enough so to be sure that it converges
                    allowParallel = TRUE,
                    tuneGrid = nnet_grid,
                    trControl = ctrl)
stopCluster(cl); remove(cl)
registerDoSEQ()
saveRDS(model_nnet, file = "C:/Documents/model_nnet.rds")
model_nnet$times$everything
plot(model_nnet)
cm_nnet <- confusionMatrix(data = predict(model_nnet, newdata = dt_test),
                           as.factor(dt_test$class))
cm_nnet

# If needed at later stage can read the rds files
SVM = readRDS(file = "C:/Documents/model_svm.rds")

#COMPARE MODELS

model_list <- list(rf = model_rf, svm = model_svm, nnet = model_nnet)
# Pass model_list to resamples()
resamples <- caret::resamples(model_list)
system.time({
  predict_rf <- raster::predict(object = brick_for_prediction_norm,
                                model = model_rf, type = 'raw')
  predict_svm <- raster::predict(object = brick_for_prediction_norm,
                                 model = model_svm, type = 'raw')
  predict_nnet <- raster::predict(object = brick_for_prediction_norm,
                                  model = model_nnet, type = 'raw')
})
sync(viewRGB(brick(rst_crop_lst[1:3]), r = 3, g = 2, b = 1) +
       mapView(poly, zcol = "class", col.regions = cls_dt$hex),
     mapView(predict_rf, col.regions = cls_dt$hex), 
     mapView(predict_svm, col.regions = cls_dt$hex),
     mapView(predict_nnet, col.regions = cls_dt$hex))

raster::writeRaster(predict_rf, "C:/Documents/RF_prediction.tiff",
                    format = "GTiff",  # output format = GeoTIFF
                    overwrite = TRUE)
raster::writeRaster(predict_svm, "C:/Documents/SVM_prediction.tiff",
                    format = "GTiff",  # output format = GeoTIFF
                    overwrite = TRUE)
raster::writeRaster(predict_nnet, "C:/Documents/NNET_prediction.tiff",
                    format = "GTiff",  # output format = GeoTIFF
                    overwrite = TRUE)


